{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMtDANnppH8bjpx5gMQDgs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktcliff/AIPlantScanClone/blob/main/SequentialModelPoisoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p25Tw712vosX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images [0:1000]\n",
        "train_labels = train_labels [0:1000]\n",
        "test_images = test_images [0:1000]\n",
        "test_labels = test_labels [0:1000]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(train_images[0])\n",
        "\n",
        "train_images = train_images.reshape(-1, 28*28)/255.0\n",
        "test_images = test_images.reshape(-1, 28*28)/255.0"
      ],
      "metadata": {
        "id": "JifrZfy0yaMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optimizer, activation_param):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Dense(512, activation=activation_param, input_shape=(784,)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "    return model"
      ],
      "metadata": {
        "id": "CcySOEMdzsVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with clean data\n",
        "model = create_model('adam', 'relu')\n",
        "\n",
        "history_clean = model.fit(train_images,\n",
        "                          train_labels,\n",
        "                          epochs=10,\n",
        "                          validation_data=(test_images, test_labels))\n",
        "\n",
        "test_score_clean, accuracy_clean = model.evaluate(test_images, test_labels)\n",
        "print(\"Clean Data Model Accuracy: \", accuracy_clean)"
      ],
      "metadata": {
        "id": "h0psMIu21DN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation accuracy and loss for clean data\n",
        "acc_clean = history_clean.history['sparse_categorical_accuracy']\n",
        "val_acc_clean = history_clean.history['val_sparse_categorical_accuracy']\n",
        "loss_clean = history_clean.history['loss']\n",
        "val_loss_clean = history_clean.history['val_loss']\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc_clean, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_clean, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy (Clean Data)')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss_clean, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_clean, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss (Clean Data)')"
      ],
      "metadata": {
        "id": "HQ9Lhv5CzBUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def poison_data(training_labels, target_label, replacement_label, number_to_replace):\n",
        "    counter = 0\n",
        "    for i in range(len(training_labels)):\n",
        "        if (training_labels[i] == target_label) & (counter <= number_to_replace):\n",
        "            training_labels[i] = replacement_label\n",
        "            counter += 1\n",
        "    return training_labels\n",
        "\n",
        "poisoned_labels = poison_data(train_labels.copy(), train_labels[0], train_labels[1], 200)"
      ],
      "metadata": {
        "id": "QJHT7RJgzh--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with poisoned data\n",
        "model_poisoned = create_model('adam', 'relu')\n",
        "history_poisoned = model_poisoned.fit(train_images,\n",
        "                                      poisoned_labels,\n",
        "                                      epochs=10,\n",
        "                                      validation_data=(test_images, test_labels))\n",
        "\n",
        "test_score_poisoned, accuracy_poisoned = model_poisoned.evaluate(test_images, test_labels)\n",
        "print(\"Poisoned Data Model Accuracy: \", accuracy_poisoned)"
      ],
      "metadata": {
        "id": "WBKVB3Jrzt-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training & validation accuracy and loss for poisoned data\n",
        "acc_poisoned = history_poisoned.history['sparse_categorical_accuracy']\n",
        "val_acc_poisoned = history_poisoned.history['val_sparse_categorical_accuracy']\n",
        "loss_poisoned = history_poisoned.history['loss']\n",
        "val_loss_poisoned = history_poisoned.history['val_loss']\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc_poisoned, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_poisoned, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy (Poisoned Data)')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss_poisoned, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_poisoned, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss (Poisoned Data)')"
      ],
      "metadata": {
        "id": "nThf5ANez8w9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}